{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection 모듈\n",
    "---\n",
    "+ 사이킷런의 model_selection 모듈은 학습 데이터와 테스트 데이터 세트를 분리하거나, 교차 검증 분할/평가, Estimator의 하이퍼 파라미터를 튜닝하기 위한 다양한 함수와 클래스 제공\n",
    "+ train_test_split()부터 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label = iris.target\n",
    "dt_clf.fit(train_data, train_label)\n",
    "\n",
    "pred = dt_clf.predict(train_data)\n",
    "print('예측 정확도: ', accuracy_score(train_label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 당연히 정확도가 100%가 나온다\n",
    "  - 이미 학습한 데이터를 대상으로 예측하면, 답을 이미 다 알고 있는 상태에서 예측이 이루어지기 때문\n",
    "  - 사이킷런의 train_test_split()을 통해 원본 데이터 세트에서 학습 및 테스트 데이터 세트를 분리해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 첫번째 파라미터로 피처 데이터 세트, 두번째 파라미터로 레이블 데이터 세트를 입력받는다\n",
    "+ 선택적으로 아래와 같은 파라미터를 입력받는다\n",
    "  - test_size: 전체 데이터에서 테스트 데이터 세트 크기를 얼마로 샘플링할 것인가 (기본값: 0.25(25%))\n",
    "  - train_size: 전체 데이터에서 학습용 데이터 세트 크기를 얼마로 샘플링할 것인가 (잘 사용되지 않음)\n",
    "  - shuffle: 데이터를 분리하기 전에 데이터를 미리 섞을지를 결정 (기본값: True)\n",
    "  - random_state: 호출할 때마다 동일한 학습/테스트 데이터 세트를 생성하기 위해 주어지는 난수 값. train_test_split()은 호출 시 무작위로 데이터를 분리하므로 이를 지정하지 않으면 수행마다 다른 학습/테스트용 데이터를 생성한다. \n",
    "+ 반환값은 튜플 형태로, (학습용-피처데이터, 테스트용-피처데이터, 학습용-레이블데이터, 테스트용-레이블데이터)의 형식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "dt_clf.fit(X_train, y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 붓꽃 데이터는 150개의 데이터로, 데이터의 양이 크지 않아 전체의 30%정도인 테스트 데이터는 45개 정도밖에 되지 않으므로 알고리즘의 성능을 판단하기에는 적절하지는 않다.\n",
    "+ 학습을 위한 데이터의 양을 일정 수준 이상 보장하는 것도 중요하지만, 학습된 모델에 대해 다양한 데이터를 기반으로 예측 성능을 평가하는 것도 중요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
